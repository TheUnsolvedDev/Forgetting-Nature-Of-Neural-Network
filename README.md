# Forgetting-Nature-Of-Neural-Network(Paper Implementation)
The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models.

Fucked up my code pretty badly still working to fix it.... Hope for the best...
